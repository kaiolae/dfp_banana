#
# Takes a trained network, and runs it with evolving goals.
#

from display_trained_agent_behavior import evaluate_a_goal_vector, mask_unused_gpus

import tensorflow as tf
from keras import backend as K
from gym_unity.envs.unity_env import UnityEnv
from dfp import DFPAgent
from networks import Networks
import numpy as np
import neat
import os
import pickle

#Some parameters
BATTERY_REFILL_AMOUNT = BATTERY_CAPACITY = 50

# Reporter helps store things on evolution-events such as generation end.
class StoreStatsReporter(neat.reporting.BaseReporter):

    def __init__(self):
        global store_to_folder
        self.generation = 0
        self.fitness_file_name = store_to_folder+"/fitness_summary.csv"
        fitness_file = open(self.fitness_file_name, "w+")
        fitness_file.write("Generation Best_Fitness Median_Fitness StdDev MedianTimeToBattEmpty MedianBattPicks MedianPoisPicks MedianFoodPicks\n")
        fitness_file.close()

        self.outputs_file_name = store_to_folder+"/nn_outputs_summary.csv"
        outputs_file = open(self.outputs_file_name, "w+")
        outputs_file.write("Generation Battery Poison Food\n")
        outputs_file.close()

        self.avg_outputs_storage_size = 0

    def start_generation(self, generation):
        self.generation = generation

    def end_generation(self, config, population, species_set):
        global stats
        global additional_statistics_storage
        # Storing fitness
        fitness_file = open(self.fitness_file_name, "a")
        fitness_file.write(str(self.generation) + " " + str(stats.best_genome().fitness)+ " " +
                           str(stats.get_fitness_median()[-1]) + " "+ str(stats.get_fitness_stdev()[-1])+" " +
                           str(np.mean(np.array(additional_statistics_storage["battery_time"]), axis=0)) + " " +
                           str(np.mean(np.array(additional_statistics_storage["battery_picks"]), axis=0)) + " " +
                           str(np.mean(np.array(additional_statistics_storage["pois_picks"]), axis=0)) + " " +
                           str(np.mean(np.array(additional_statistics_storage["food_picks"]), axis=0)) + "\n")


        additional_statistics_storage["battery_time"] = []
        additional_statistics_storage["battery_picks"] = []
        additional_statistics_storage["pois_picks"] = []
        additional_statistics_storage["food_picks"] = []

        # Storing NN outputs
        avg_nn_outputs_this_generation = avg_outputs_storage[self.avg_outputs_storage_size:]
        outputs_file = open(self.outputs_file_name, "a")
        for individual_outputs in avg_nn_outputs_this_generation:
            outputs_file.write(str(self.generation))
            for outputs in individual_outputs:
                outputs_file.write(" "+str(outputs))
            outputs_file.write("\n")
        self.avg_outputs_storage_size = len(avg_outputs_storage)

#EA code based on NEAT XOR example
def eval_genomes(genomes, config):
    global avg_outputs_storage
    global env
    global dfp_net
    global additional_statistics_storage
    for genome_id, genome in genomes:
        net = neat.nn.FeedForwardNetwork.create(genome, config)
        eval_result = evaluate_a_goal_vector([0,0,0], env, dfp_net, goal_producing_network=net, display=False, battery_refill_amount=BATTERY_REFILL_AMOUNT, initial_battery=BATTERY_CAPACITY)
        #We want to store the average outputs generated by the NN to see how the coeffs evolve over generations.
        #TODO Later, I may want to store all this rather than average. Maybe I can see interesting trends of how different objectives are prioritized at different points in agent's life?
        print("All nn output shape: ", np.array(eval_result["goal_history"]).shape)
        avg_nn_outputs = np.mean(np.array(eval_result["goal_history"]), axis=0)
        print("Avg nn outputs was: ", avg_nn_outputs)
        avg_outputs_storage.append(avg_nn_outputs)
        additional_statistics_storage["battery_time"].append(eval_result["num_timesteps_elapsed"])
        additional_statistics_storage["battery_picks"].append(eval_result["battery_picks"])
        additional_statistics_storage["pois_picks"].append(eval_result["poison"])
        additional_statistics_storage["food_picks"].append(eval_result["food"])

        #KOE: Here, I can choose what to optimize for: Battery, food, poison, etc.
        #How about food minus poison? Battery could take care of itself if we set up the "dead if no battery" rule?
        genome.fitness = eval_result["food"]-eval_result["poison"]
        #print("Eval result was ", eval_result)
        print("fitness was: ", genome.fitness)

def run_neat(config_file="config"):
    global stats
    global store_to_folder
    # Load configuration.
    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,
                         neat.DefaultSpeciesSet, neat.DefaultStagnation,
                         config_file)

    # Create the population, which is the top-level object for a NEAT run.
    p = neat.Population(config)

    # Add a stdout reporter to show progress in the terminal.
    p.add_reporter(neat.StdOutReporter(True))
    p.add_reporter(stats)
    p.add_reporter(neat.Checkpointer(15,None))
    p.add_reporter(
        StoreStatsReporter())  # KOE: My own reporter, that dumps progress to file as we go, allowing statistics on the fly.

    # 50 indivs seems to give 15 min per generation. 100 gen in 1 day, 250 in a weekend run.
    winner = p.run(eval_genomes, 100)  #TODO Seems around 25-50 was enough.

    # Display the winning genome.
    print('\nBest genome:\n{!s}'.format(winner))
    pickle.dump(winner,
                open(store_to_folder + "/winner_network.pickle", "wb"))  # Stored winner network. Load later and test.

    # Show output of the most fit genome against training data.
    print('\nOutput:')
    winner_net = neat.nn.FeedForwardNetwork.create(winner, config)

    stats.save_genome_fitness()
    visualize.plot_stats(stats, ylog=False, view=False)
    # visualize.plot_species(stats, view=True)

if __name__ == "__main__":
    ##Some parameters



    global store_to_folder
    store_to_folder = "aug2_evo_test_battery_capacity_" + str(BATTERY_CAPACITY) + "/" #TODO: Add as input argument
    print("***************Storing results to folder ", store_to_folder, "*********************************")
    if not os.path.exists(store_to_folder):
        os.makedirs(store_to_folder)

    # Stores average NN outputs. TODO Here we should also somehow store the generation number. Look into if NEAT allows that.
    global avg_outputs_storage
    avg_outputs_storage = []

    global additional_statistics_storage
    additional_statistics_storage = {}
    additional_statistics_storage["battery_time"] = []
    additional_statistics_storage["battery_picks"] = []
    additional_statistics_storage["pois_picks"] = []
    additional_statistics_storage["food_picks"] = []

    mask_unused_gpus()

    # Avoid Tensorflow eats up GPU memory
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)
    K.set_session(sess)

    #Setting up the env
    #TODO Worker_id can be changed to run in parallell
    #Flatten_branched gives us a onehot encoding of all 54 action combinations.
    print("Opening unity env")
    global env
    env = UnityEnv("../unity_envs/kais_banana_with_battery_consumable_balanced", worker_id=50, use_visual=True, flatten_branched=True)

    measurement_size = 3
    timesteps = [1, 2, 4, 8, 16, 32]
    goal_size = measurement_size * len(timesteps)
    img_rows, img_cols = 84, 84
    img_channels = 3  # KOE: If I want to change this, I have to also edit the frame stacking when forming s_t
    state_size = (img_rows, img_cols, img_channels)


    action_size = env.action_space.n
    print("Env has ", action_size, " actions.")

    global dfp_net
    dfp_net = DFPAgent(state_size, measurement_size, action_size, timesteps)
    dfp_net.model = Networks.dfp_network(state_size, measurement_size, goal_size, action_size, len(timesteps), dfp_net.learning_rate)

    loaded_model = "june27_battery_balanced1_agnostic_battery_limit_on/model/dfp.h5" #KOE: This was trained with real battery consequences. It seemed to learn battery seeking behavior better.
    dfp_net.load_model(loaded_model)
    dfp_net.epsilon = dfp_net.final_epsilon

    global stats
    stats = neat.StatisticsReporter()

    # Configuring NEAT
    run_neat("config")

    avg_outputs_storage = np.array(avg_outputs_storage)
    np.savetxt(store_to_folder + "/evolving_nn_outputs.csv", avg_outputs_storage, delimiter=" ")

    env.close()
